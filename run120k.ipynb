{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9502dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211207_10_MPA_STD_01.txt\n",
      "20211207_11_MPA_A_01.txt\n",
      "20211207_12_MPA_STD_02.txt\n",
      "20211207_13_MPA_A_02.txt\n",
      "20211207_14_MPA_STD_03.txt\n",
      "20211207_15_MPA_A_03.txt\n",
      "20211207_16_MPA_STD_04.txt\n",
      "20211207_17_MPA_F_01.txt\n",
      "20211207_18_MPA_STD_05.txt\n",
      "20211207_19_MPA_F_02.txt\n",
      "20211207_20_MPA_STD_06.txt\n",
      "20211207_21_MPA_F_03.txt\n",
      "20211207_22_MPA_STD_07.txt\n",
      "20211208_11_MPA_STD_01.txt\n",
      "20211208_12_MPA_K_01.txt\n",
      "20211208_13_MPA_STD_02.txt\n",
      "20211208_14_MPA_K_02.txt\n",
      "20211208_15_MPA_STD_03.txt\n",
      "20211208_16_MPA_K_03.txt\n",
      "20211208_17_MPA_STD_04.txt\n",
      "20211208_18_MPA_I_01.txt\n",
      "20211208_19_MPA_STD_05.txt\n",
      "20211208_20_MPA_I_02.txt\n",
      "20211208_21_MPA_STD_06.txt\n",
      "20211208_22_MPA_I_03.txt\n",
      "20211208_23_MPA_STD_04.txt\n",
      "20211209_05_MPA_STD_01.txt\n",
      "20211209_06_MPA_M_01.txt\n",
      "20211209_07_MPA_STD_02.txt\n",
      "20211209_08_MPA_M_02.txt\n",
      "20211209_09_MPA_STD_03.txt\n",
      "20211209_10_MPA_M_03.txt\n",
      "20211209_11_MPA_STD_04.txt\n",
      "20211210_09_MPA_STD_01.txt\n",
      "20211210_10_MPA_C_01.txt\n",
      "20211210_11_MPA_STD_01_Repeat.txt\n",
      "20211210_12_MPA_C_02.txt\n",
      "20211210_13_MPA_STD_03.txt\n",
      "20211210_14_MPA_C_03.txt\n",
      "20211210_15_MPA_STD_04.txt\n",
      "20230502_02_MPA_SIG_STD_01.txt\n",
      "20230502_03_MPA_THR2_SMP_01.txt\n",
      "20230502_04_MPA_SIG_STD_01.txt\n",
      "20230502_05_MPA_THR2_SMP_02.txt\n",
      "20230502_06_MPA_SIG_STD_03.txt\n",
      "20230502_07_MPA_THR2_SMP_03.txt\n",
      "20230502_08_MPA_SIG_STD_04.txt\n",
      "20230502_09_MPA_ARC_SMP_01.txt\n",
      "20230502_10_MPA_SIG_STD_02.txt\n",
      "20230502_11_MPA_ARC_SMP_02.txt\n",
      "20230502_12_MPA_SIG_STD_03.txt\n",
      "20230502_13_MPA_ARC_SMP_03.txt\n",
      "20230502_14_MPA_SIG_STD_04.txt\n",
      "20230503_01_MPA_SIG_STD_01.txt\n",
      "20230503_02_MPA_BTC_SMP_01.txt\n",
      "20230503_03_MPA_SIG_STD_02.txt\n",
      "20230503_04_MPA_BTC_SMP_02.txt\n",
      "20230503_05_MPA_SIG_STD_03.txt\n",
      "20230503_06_MPA_BTC_SMP_03.txt\n",
      "20230503_07_MPA_SIG_STD_04.txt\n",
      "20230503_08_MPA_THR1_SMP_01.txt\n",
      "20230503_09_MPA_SIG_STD_02.txt\n",
      "20230503_10_MPA_THR1_SMP_02.txt\n",
      "20230503_11_MPA_SIG_STD_03.txt\n",
      "20230503_12_MPA_THR1_SMP_03.txt\n",
      "20230503_13_MPA_SIG_STD_04.txt\n",
      "File 43 96 17O/Unsub fails RSE/SN Test with value of 2.1203293605209517\n",
      "File 47 96 17O/Unsub fails RSE/SN Test with value of 2.2724700003823544\n",
      "File 48 96 17O/Unsub fails RSE/SN Test with value of 2.289499231978338\n",
      "20230502_05_MPA_THR2_SMP_02.txt 17O has 3 zero scans, out of 509 scans (0.005893909626719057)\n",
      "20230502_09_MPA_ARC_SMP_01.txt 17O has 2 zero scans, out of 445 scans (0.0044943820224719105)\n",
      "20230502_10_MPA_SIG_STD_02.txt 17O has 2 zero scans, out of 472 scans (0.00423728813559322)\n",
      "18O\n",
      "Failed Subsequence Detection 20211207_12_MPA_STD_02.txt 18O with a value of 0.65\n",
      "Failed Subsequence Detection 20211207_13_MPA_A_02.txt 18O with a value of 0.69\n",
      "Failed Subsequence Detection 20211207_22_MPA_STD_07.txt 18O with a value of 0.69\n",
      "Failed Subsequence Detection 20211208_13_MPA_STD_02.txt 18O with a value of 0.70\n",
      "Failed Subsequence Detection 20211208_19_MPA_STD_05.txt 18O with a value of 0.70\n",
      "Failed Subsequence Detection 20211210_09_MPA_STD_01.txt 18O with a value of 0.89\n",
      "Failed Subsequence Detection 20211210_10_MPA_C_01.txt 18O with a value of 0.76\n",
      "Failed Subsequence Detection 20211210_11_MPA_STD_01_Repeat.txt 18O with a value of 0.89\n",
      "Failed Subsequence Detection 20230502_04_MPA_SIG_STD_01.txt 18O with a value of 0.69\n",
      "Failed Subsequence Detection 20230502_12_MPA_SIG_STD_03.txt 18O with a value of 0.65\n",
      "D\n",
      "Failed Subsequence Detection 20211208_23_MPA_STD_04.txt D with a value of 0.64\n",
      "17O\n",
      "Failed Subsequence Detection 20211207_18_MPA_STD_05.txt 17O with a value of 0.68\n",
      "Failed Subsequence Detection 20211207_21_MPA_F_03.txt 17O with a value of 0.65\n",
      "Failed Subsequence Detection 20211208_15_MPA_STD_03.txt 17O with a value of 0.73\n",
      "Failed Subsequence Detection 20211209_06_MPA_M_01.txt 17O with a value of 0.64\n",
      "Failed Subsequence Detection 20230502_10_MPA_SIG_STD_02.txt 17O with a value of 1.34\n",
      "13C\n",
      "Unsub\n",
      "20230502_05_MPA_THR2_SMP_02.txt 0.20 has TIC*IT RSD greater than threshold\n",
      "20230502_07_MPA_THR2_SMP_03.txt 0.13 has TIC*IT RSD greater than threshold\n",
      "20230502_09_MPA_ARC_SMP_01.txt 0.23 has TIC*IT RSD greater than threshold\n",
      "20230502_10_MPA_SIG_STD_02.txt 0.34 has TIC*IT RSD greater than threshold\n"
     ]
    }
   ],
   "source": [
    "#search for import above the current directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "cwd = Path().resolve()\n",
    "\n",
    "sys.path.insert(1, os.path.join(cwd, 'Read Process CSV'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from scipy import stats\n",
    "\n",
    "import dataAnalyzer_FTStat\n",
    "import dataScreen_FTStat\n",
    "import orbiStandardize\n",
    "\n",
    "#Set up the inputs\n",
    "\n",
    "#Folder with FT Statistic-ified files. All the files need to be processed using the same metrics.\n",
    "folderPath = \"Orbi_120k\"\n",
    "SmpStd = ['Std','A'] * 3 + ['Std','F'] * 3 + ['Std'] + ['Std','K'] * 3 + ['Std','I'] * 3 + ['Std'] + ['Std','M'] * 3 + ['Std'] + ['Std','C'] * 3 + ['Std'] + ['Std','THR2'] * 3 + ['Std','ARC'] * 3 + ['Std'] + ['Std','BTC'] * 3 + ['Std','THR1'] * 3 + ['Std']\n",
    "Replicate = ['1','1','2','2','3','3','4','1','1','2','2','3','3'] * 2 + ['1','1','2','2','3','3','4'] * 2\n",
    "\n",
    "fragmentDict = {'96':['18O','D','17O','13C','Unsub']}\n",
    "\n",
    "fragmentMostAbundant = ['Unsub']\n",
    "\n",
    "massStr = []\n",
    "fragmentIsotopeList = []\n",
    "for i, v in fragmentDict.items():\n",
    "    massStr.append(i)\n",
    "    fragmentIsotopeList.append(v)\n",
    "    \n",
    "cullByTime = True\n",
    "cullTimes = [(3,40)]\n",
    "\n",
    "#Any specific properties you want to cull on\n",
    "cullOn = \"TIC*IT\"\n",
    "#Multiple of SD you want to cull beyond for the cullOn property\n",
    "cull_amount = 3\n",
    "#Whether you want to cull zero scans\n",
    "cullZeroScans = False\n",
    "#Whether you want to calculate weighted averages based on NL height (specifically designed for GC elution but widely applicable!)\n",
    "weightByNLHeight = False\n",
    "#Whether you want to output each file as you process it, and where you want it to go:\n",
    "fileOutputPath = None\n",
    "\n",
    "percentAbundance = False\n",
    "\n",
    "extractedData120k = {}\n",
    "\n",
    "rtnAllFilesDF, mergedDict, allOutputDict = dataAnalyzer_FTStat.calc_Folder_Output(folderPath, cullOn=cullOn, cullAmount=cull_amount,\n",
    "                                               cullByTime=cullByTime, cullTimes = cullTimes, \n",
    "                                               fragmentIsotopeList = fragmentIsotopeList, \n",
    "                                               fragmentMostAbundant = fragmentMostAbundant, debug = True, fileExt = '.txt', \n",
    "                                               massStrList = list(fragmentDict.keys()),\n",
    "                                               Microscans = 10)\n",
    "\n",
    "failedRSE = dataScreen_FTStat.RSESNScreen(allOutputDict)\n",
    "failedZero = dataScreen_FTStat.zeroCountsScreen(mergedDict, fragmentDict['96'], threshold = 0)\n",
    "failedInternal = dataScreen_FTStat.internalStabilityScreenSubsequence(mergedDict, fragmentDict['96'], 'Unsub', priorSubsequenceLength = 100, testSubsequenceLength = 100, thresholdConstant = 0.64)\n",
    "failedTICIT = dataScreen_FTStat.TICITScreen(mergedDict)\n",
    "\n",
    "fileKeys = list(mergedDict.keys())\n",
    "for subKey, subData in failedRSE.items():\n",
    "    failedRSE[subKey] = [fileKeys[x] for x in subData]\n",
    "\n",
    "failedAny = {}\n",
    "for subKey, subData in failedRSE.items():\n",
    "    failedAny[subKey + '/Unsub'] = set(subData) | set(failedZero[subKey]) | set(failedZero['Unsub']) | set(failedInternal[subKey]) | set(failedInternal['Unsub']) | set(failedTICIT)\n",
    "\n",
    "extractedData120k = dataAnalyzer_FTStat.folderOutputToDict(rtnAllFilesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36044011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'18O/Unsub': {'20211207_12_MPA_STD_02.txt',\n",
       "  '20211207_13_MPA_A_02.txt',\n",
       "  '20211207_22_MPA_STD_07.txt',\n",
       "  '20211208_13_MPA_STD_02.txt',\n",
       "  '20211208_19_MPA_STD_05.txt',\n",
       "  '20211210_09_MPA_STD_01.txt',\n",
       "  '20211210_10_MPA_C_01.txt',\n",
       "  '20211210_11_MPA_STD_01_Repeat.txt',\n",
       "  '20230502_04_MPA_SIG_STD_01.txt',\n",
       "  '20230502_05_MPA_THR2_SMP_02.txt',\n",
       "  '20230502_07_MPA_THR2_SMP_03.txt',\n",
       "  '20230502_09_MPA_ARC_SMP_01.txt',\n",
       "  '20230502_10_MPA_SIG_STD_02.txt',\n",
       "  '20230502_12_MPA_SIG_STD_03.txt'},\n",
       " 'D/Unsub': {'20211208_23_MPA_STD_04.txt',\n",
       "  '20230502_05_MPA_THR2_SMP_02.txt',\n",
       "  '20230502_07_MPA_THR2_SMP_03.txt',\n",
       "  '20230502_09_MPA_ARC_SMP_01.txt',\n",
       "  '20230502_10_MPA_SIG_STD_02.txt'},\n",
       " '17O/Unsub': {'20211207_18_MPA_STD_05.txt',\n",
       "  '20211207_21_MPA_F_03.txt',\n",
       "  '20211208_15_MPA_STD_03.txt',\n",
       "  '20211209_06_MPA_M_01.txt',\n",
       "  '20230502_05_MPA_THR2_SMP_02.txt',\n",
       "  '20230502_07_MPA_THR2_SMP_03.txt',\n",
       "  '20230502_09_MPA_ARC_SMP_01.txt',\n",
       "  '20230502_10_MPA_SIG_STD_02.txt'},\n",
       " '13C/Unsub': {'20230502_05_MPA_THR2_SMP_02.txt',\n",
       "  '20230502_07_MPA_THR2_SMP_03.txt',\n",
       "  '20230502_09_MPA_ARC_SMP_01.txt',\n",
       "  '20230502_10_MPA_SIG_STD_02.txt'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failedAny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4542fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkThresholdConstant = False\n",
    "if checkThresholdConstant:\n",
    "    maxes = []\n",
    "    for i in tqdm(range(1000)):\n",
    "        array = np.random.normal(size = 4570)\n",
    "\n",
    "        # Reshape the array into a 2D array with 10 columns\n",
    "        num_rows = 4570 // 10\n",
    "        reshaped_array = array[:num_rows * 10].reshape(num_rows, 10)\n",
    "\n",
    "        # Calculate the average along axis 1 (columns)\n",
    "        averages = np.mean(reshaped_array, axis=1)\n",
    "\n",
    "        outlier = dataScreen_FTStat.subsequenceOutlierDetection(pd.Series(averages), priorSubsequenceLength = 100, testSubsequenceLength = 100)\n",
    "        maxes.append(outlier.max())\n",
    "\n",
    "    np.array(maxes).mean() + 4 * np.array(maxes).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8beba70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkTIC = False\n",
    "if checkTIC:\n",
    "    for thisSmp in ['A','F','K','I','M','C','ARC','BTC','THR1','THR2']:\n",
    "        firstIdx = SmpStd.index(thisSmp)\n",
    "        thisSmpIndices = [firstIdx, firstIdx + 2, firstIdx + 4]\n",
    "        thisStdIndices = [firstIdx-1, firstIdx +1, firstIdx + 3, firstIdx +5]\n",
    "\n",
    "        allSmpTic = []\n",
    "        for smpIdx in thisSmpIndices:\n",
    "            smpName = list(mergedDict.keys())[smpIdx]\n",
    "            thisDf = mergedDict[smpName][0]\n",
    "            allSmpTic += list(thisDf['tic'])\n",
    "\n",
    "        allStdTic = []\n",
    "        for stdIdx in thisStdIndices:\n",
    "            stdName = list(mergedDict.keys())[stdIdx]\n",
    "            thisDf = mergedDict[stdName][0]\n",
    "            allStdTic += list(thisDf['tic'])\n",
    "\n",
    "        smpTic = np.array(allSmpTic)\n",
    "        stdTic = np.array(allStdTic)\n",
    "        print(thisSmp + ' ' + f'{smpTic.mean():.2f}' + ' ' + f'{smpTic.std() / smpTic.mean():.2f}')\n",
    "        print( f'{stdTic.mean():.2f}' + ' ' + f'{stdTic.std() / stdTic.mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153974e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "byIndex = {}\n",
    "bySample = {}\n",
    "for thisSmp in ['A','F','K','I','M','C','ARC','BTC','THR1','THR2']:\n",
    "    bySample[thisSmp] = {}\n",
    "    firstIdx = SmpStd.index(thisSmp)\n",
    "    thisIndices = list(range(firstIdx -1, firstIdx + 6))\n",
    "    byIndex[thisSmp] = thisIndices\n",
    "\n",
    "    for ratioKey in ['13C/Unsub','D/Unsub']:\n",
    "        valDict = orbiStandardize.extractThisRun(extractedData120k, failedAny, thisIndices, ratioKey)\n",
    "        vals, errs = orbiStandardize.standardizeOneRun(valDict['Avg'], valDict['RelStdError'], standardize = 'linear')\n",
    "        deltas = 1000*(vals-1)\n",
    "\n",
    "        bySample[thisSmp][ratioKey] = {}\n",
    "        bySample[thisSmp][ratioKey]['Ratios'] = list(vals)\n",
    "        bySample[thisSmp][ratioKey]['RSEs'] = list(errs)\n",
    "        bySample[thisSmp][ratioKey]['Deltas'] = list(deltas)\n",
    "        bySample[thisSmp][ratioKey]['DeltasErr'] = list(1000*errs)\n",
    "        bySample[thisSmp][ratioKey]['Delta Mean'] = deltas.mean()\n",
    "        bySample[thisSmp][ratioKey]['ER'] = deltas.std()\n",
    "\n",
    "with open('120k_Data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(bySample, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8c552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orbitrap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
